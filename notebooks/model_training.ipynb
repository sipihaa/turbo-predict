{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "71c499bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import git\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c430d1bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Git Commit Hash: d6b880d9fe992c219be8419385acc56b105d2775\n"
     ]
    }
   ],
   "source": [
    "# –£–∫–∞–∑—ã–≤–∞–µ–º MLflow, –∫—É–¥–∞ –æ—Ç–ø—Ä–∞–≤–ª—è—Ç—å –¥–∞–Ω–Ω—ã–µ\n",
    "mlflow.set_tracking_uri(\"http://213.21.252.250:5000\")\n",
    "\n",
    "# –ó–∞–¥–∞–µ–º –∏–º—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞\n",
    "mlflow.set_experiment(\"LSTM (test)\")\n",
    "\n",
    "# --- –ü–æ–ª—É—á–∞–µ–º —Ö–µ—à –∫–æ–º–º–∏—Ç–∞ Git ---\n",
    "try:\n",
    "    repo = git.Repo(search_parent_directories=True)\n",
    "    git_commit_hash = repo.head.object.hexsha\n",
    "except Exception as e:\n",
    "    git_commit_hash = \"N/A\" # –ù–∞ —Å–ª—É—á–∞–π, –µ—Å–ª–∏ —Å–∫—Ä–∏–ø—Ç –∑–∞–ø—É—â–µ–Ω –Ω–µ –∏–∑ Git-—Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è\n",
    "    print(f\"Warning: Could not get git commit hash. {e}\")\n",
    "\n",
    "print(f\"Current Git Commit Hash: {git_commit_hash}\")\n",
    "\n",
    "# --- –ü–∞—Ä–∞–º–µ—Ç—Ä—ã, –∫–æ—Ç–æ—Ä—ã–µ –Ω—É–∂–Ω–æ –ª–æ–≥–∏—Ä–æ–≤–∞—Ç—å ---\n",
    "# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–∑ —Å–∫—Ä–∏–ø—Ç–∞ –Ω–∞—Ä–µ–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö (sample_creator)\n",
    "data_params = {\n",
    "    \"window_size\": 50,\n",
    "    \"step\": 1,\n",
    "    \"sampling_rate\": 10\n",
    "}\n",
    "\n",
    "# –ì–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏\n",
    "model_params = {\n",
    "    \"epochs\": 20,\n",
    "    \"batch_size\": 128,\n",
    "    \"validation_split\": 0.2,\n",
    "    \"optimizer\": \"adam\",\n",
    "    \"loss\": \"mean_squared_error\",\n",
    "    \"lr\": 0.002\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "30ab700d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting MLflow run...\n",
      "Parameters logged.\n",
      "['../data/processed/Unit16_win50_str1_smp10.npz', '../data/processed/Unit5_win50_str1_smp10.npz', '../data/processed/Unit18_win50_str1_smp10.npz', '../data/processed/Unit20_win50_str1_smp10.npz', '../data/processed/Unit2_win50_str1_smp10.npz', '../data/processed/Unit10_win50_str1_smp10.npz']\n",
      "–†–∞–∑–º–µ—Ä –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–∏ (X): (526051, 50, 20)\n",
      "–†–∞–∑–º–µ—Ä –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–∏ (y): (526051,)\n",
      "–†–∞–∑–º–µ—Ä —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–∏ (X): (125227, 50, 20)\n",
      "–†–∞–∑–º–µ—Ä —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–∏ (y): (125227,)\n",
      "Epoch [1/8], rain oss: 800.3645, Val Loss: 502.4489, Val MAE: 19.1274\n",
      "Epoch [2/8], rain oss: 533.0172, Val Loss: 499.9115, Val MAE: 19.1139\n",
      "Epoch [3/8], rain oss: 527.9903, Val Loss: 429.6263, Val MAE: 16.6677\n",
      "Epoch [4/8], rain oss: 109.1784, Val Loss: 48.6305, Val MAE: 4.9650\n",
      "Epoch [5/8], rain oss: 80.0861, Val Loss: 48.2474, Val MAE: 4.8366\n",
      "Epoch [6/8], rain oss: 75.6794, Val Loss: 40.7027, Val MAE: 4.4815\n",
      "Epoch [7/8], rain oss: 71.1055, Val Loss: 39.9005, Val MAE: 4.4522\n",
      "Epoch [8/8], rain oss: 68.5406, Val Loss: 53.3828, Val MAE: 5.1535\n",
      "\n",
      "Test MAE: 4.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/19 14:32:14 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics logged: {'mae': 4.726075934993653}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/11/19 14:32:17 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished.\n",
      "üèÉ View run loud-sloth-557 at: http://213.21.252.250:5000/#/experiments/1/runs/e96964571d78402998b5ecf39877d4af\n",
      "üß™ View experiment at: http://213.21.252.250:5000/#/experiments/1\n",
      "Model logged as an artifact.\n",
      "MLflow run finished successfully!\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run():\n",
    "    print(\"Starting MLflow run...\")\n",
    "\n",
    "    # --- –õ–æ–≥–∏—Ä—É–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã ---\n",
    "    mlflow.log_params(data_params)\n",
    "    mlflow.log_params(model_params)\n",
    "    mlflow.set_tag(\"git_commit\", git_commit_hash)\n",
    "    print(\"Parameters logged.\")\n",
    "\n",
    "    def load_and_merge_data(npz_units):\n",
    "      sample_array_lst = []\n",
    "      label_array_lst = []\n",
    "      for npz_unit in npz_units:\n",
    "        loaded = np.load(npz_unit)\n",
    "        sample_array_lst.append(loaded['sample'])\n",
    "        label_array_lst.append(loaded['label'])\n",
    "      sample_array = np.dstack(sample_array_lst)\n",
    "      label_array = np.concatenate(label_array_lst)\n",
    "      sample_array = sample_array.transpose(2, 0, 1)\n",
    "      return sample_array, label_array\n",
    "\n",
    "    processed_dir = '../data/processed/'\n",
    "\n",
    "    # –°–æ–±–∏—Ä–∞–µ–º –ø—É—Ç–∏ –∫ —Ñ–∞–π–ª–∞–º –¥–ª—è train –∏ test\n",
    "    train_files = [os.path.join(processed_dir, f) for f in os.listdir(processed_dir) if f.startswith(('Unit2_', 'Unit5_', 'Unit10_', 'Unit16_', 'Unit18_', 'Unit20_'))]\n",
    "    test_files = [os.path.join(processed_dir, f) for f in os.listdir(processed_dir) if f.startswith(('Unit11_', 'Unit14_', 'Unit15_'))]\n",
    "    print(train_files)\n",
    "\n",
    "    # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ\n",
    "    X_train, y_train = load_and_merge_data(train_files)\n",
    "    X_test, y_test = load_and_merge_data(test_files)\n",
    "\n",
    "    print('–†–∞–∑–º–µ—Ä –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–∏ (X):', X_train.shape)\n",
    "    print('–†–∞–∑–º–µ—Ä –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–∏ (y):', y_train.shape)\n",
    "    print('–†–∞–∑–º–µ—Ä —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–∏ (X):', X_test.shape)\n",
    "    print('–†–∞–∑–º–µ—Ä —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–∏ (y):', y_test.shape)\n",
    "\n",
    "    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ñ–æ—Ä–º—É –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∏–∑ X_train\n",
    "    n_timesteps, n_features = X_train.shape[1], X_train.shape[2]\n",
    "\n",
    "    # --- –û–ø—Ä–µ–¥–µ–ª—è–µ–º –º–æ–¥–µ–ª—å LSTM –Ω–∞ PyTorch ---\n",
    "    class LSTMModel(nn.Module):\n",
    "        def __init__(self, input_dim, hidden_dim_1, hidden_dim_2, output_dim=1, dropout_prob=0.2):\n",
    "            super(LSTMModel, self).__init__()\n",
    "            # –ü–µ—Ä–≤—ã–π LSTM —Å–ª–æ–π\n",
    "            self.lstm1 = nn.LSTM(input_dim, hidden_dim_1, batch_first=True)\n",
    "            # batch_first=True –æ—á–µ–Ω—å –≤–∞–∂–µ–Ω, —á—Ç–æ–±—ã –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏–º–µ–ª–∏ —Ñ–æ—Ä–º–∞—Ç (batch, seq, feature), –∫–∞–∫ –≤ Keras\n",
    "            \n",
    "            self.dropout1 = nn.Dropout(dropout_prob)\n",
    "            \n",
    "            # –í—Ç–æ—Ä–æ–π LSTM —Å–ª–æ–π\n",
    "            # –û–Ω –ø—Ä–∏–Ω–∏–º–∞–µ—Ç –Ω–∞ –≤—Ö–æ–¥ —Å–∫—Ä—ã—Ç–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –ø–µ—Ä–≤–æ–≥–æ —Å–ª–æ—è (hidden_dim_1)\n",
    "            self.lstm2 = nn.LSTM(hidden_dim_1, hidden_dim_2, batch_first=True)\n",
    "            \n",
    "            self.dropout2 = nn.Dropout(dropout_prob)\n",
    "            \n",
    "            # –ü–æ–ª–Ω–æ—Å–≤—è–∑–Ω—ã–π —Å–ª–æ–π –¥–ª—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –ø—Ä–æ–≥–Ω–æ–∑–∞\n",
    "            self.fc = nn.Linear(hidden_dim_2, output_dim)\n",
    "\n",
    "        def forward(self, x):\n",
    "            # –ü–µ—Ä–≤—ã–π LSTM —Å–ª–æ–π\n",
    "            # LSTM –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç output –∏ –∫–æ—Ä—Ç–µ–∂ (hidden_state, cell_state)\n",
    "            # –ù–∞–º –Ω—É–∂–µ–Ω output –¥–ª—è —Å–ª–µ–¥—É—é—â–µ–≥–æ —Å–ª–æ—è\n",
    "            lstm1_out, _ = self.lstm1(x)\n",
    "            \n",
    "            # Dropout\n",
    "            out = self.dropout1(lstm1_out)\n",
    "            \n",
    "            # –í—Ç–æ—Ä–æ–π LSTM —Å–ª–æ–π\n",
    "            # –ù–∞–º –Ω—É–∂–µ–Ω —Ç–æ–ª—å–∫–æ –≤—ã—Ö–æ–¥ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —à–∞–≥–∞\n",
    "            lstm2_out, _ = self.lstm2(out)\n",
    "            last_hidden_state = lstm2_out[:, -1, :] # –ë–µ—Ä–µ–º –≤—ã—Ö–æ–¥ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏\n",
    "            \n",
    "            # Dropout\n",
    "            out = self.dropout2(last_hidden_state)\n",
    "            \n",
    "            # –ü–æ–ª–Ω–æ—Å–≤—è–∑–Ω—ã–π —Å–ª–æ–π\n",
    "            final_output = self.fc(out)\n",
    "            return final_output\n",
    "\n",
    "    # --- –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è PyTorch ---\n",
    "    # 1. –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º numpy –º–∞—Å—Å–∏–≤—ã –≤ torch —Ç–µ–Ω–∑–æ—Ä—ã\n",
    "    X_train_tensor = torch.from_numpy(X_train).float()\n",
    "    y_train_tensor = torch.from_numpy(y_train).float().view(-1, 1) # –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ —Ñ–æ—Ä–º–∞ (batch_size, 1)\n",
    "    X_test_tensor = torch.from_numpy(X_test).float()\n",
    "    y_test_tensor = torch.from_numpy(y_test).float().view(-1, 1)\n",
    "\n",
    "    # 2. –°–æ–∑–¥–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç—ã\n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "    # 3. –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ –æ–±—É—á–∞—é—â—É—é –∏ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—É—é –≤—ã–±–æ—Ä–∫–∏ –≤—Ä—É—á–Ω—É—é\n",
    "    val_split = model_params['validation_split']\n",
    "    dataset_size = len(train_dataset)\n",
    "    val_size = int(val_split * dataset_size)\n",
    "    train_size = dataset_size - val_size\n",
    "    train_subset, val_subset = torch.utils.data.random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "    # 4. –°–æ–∑–¥–∞–µ–º –∑–∞–≥—Ä—É–∑—á–∏–∫–∏ –¥–∞–Ω–Ω—ã—Ö (DataLoader), –∫–æ—Ç–æ—Ä—ã–µ –±—É–¥—É—Ç –ø–æ–¥–∞–≤–∞—Ç—å –¥–∞–Ω–Ω—ã–µ –±–∞—Ç—á–∞–º–∏\n",
    "    train_loader = DataLoader(dataset=train_subset, batch_size=model_params['batch_size'], shuffle=True)\n",
    "    val_loader = DataLoader(dataset=val_subset, batch_size=model_params['batch_size'])\n",
    "    test_loader = DataLoader(dataset=test_dataset, batch_size=model_params['batch_size'])\n",
    "\n",
    "    # --- –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏, –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞ –∏ —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å ---\n",
    "    model = LSTMModel(input_dim=n_features, hidden_dim_1=16, hidden_dim_2=8)\n",
    "\n",
    "    # –í—ã–±–∏—Ä–∞–µ–º —Ñ—É–Ω–∫—Ü–∏—é –ø–æ—Ç–µ—Ä—å (–∞–Ω–∞–ª–æ–≥ 'loss' –≤ Keras)\n",
    "    if model_params['loss'] == 'mse':\n",
    "        criterion = nn.MSELoss()\n",
    "    else:\n",
    "        # –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –¥—Ä—É–≥–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å\n",
    "        criterion = nn.MSELoss() \n",
    "\n",
    "    # –í—ã–±–∏—Ä–∞–µ–º –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä (–∞–Ω–∞–ª–æ–≥ 'optimizer' –≤ Keras)\n",
    "    if model_params['optimizer'] == 'adam':\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=model_params['lr'])\n",
    "    else:\n",
    "        # –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –¥—Ä—É–≥–∏–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä—ã\n",
    "        optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "    # --- –¶–∏–∫–ª –æ–±—É—á–µ–Ω–∏—è ---\n",
    "    for epoch in range(model_params['epochs']):\n",
    "        model.train() # –ü–µ—Ä–µ–≤–æ–¥–∏–º –º–æ–¥–µ–ª—å –≤ —Ä–µ–∂–∏–º –æ–±—É—á–µ–Ω–∏—è\n",
    "        running_loss = 0.0\n",
    "        for i, (inputs, labels) in enumerate(train_loader):\n",
    "            # 1. –û–±–Ω—É–ª—è–µ–º –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã\n",
    "            optimizer.zero_grad()\n",
    "            # 2. –ü—Ä—è–º–æ–π –ø—Ä–æ—Ö–æ–¥ (forward pass)\n",
    "            outputs = model(inputs)\n",
    "            # 3. –†–∞—Å—á–µ—Ç —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å\n",
    "            loss = criterion(outputs, labels)\n",
    "            # 4. –û–±—Ä–∞—Ç–Ω—ã–π –ø—Ä–æ—Ö–æ–¥ (backward pass)\n",
    "            loss.backward()\n",
    "            # 5. –®–∞–≥ –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        # –†–∞—Å—á–µ—Ç –∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Å—Ä–µ–¥–Ω–µ–π –ø–æ—Ç–µ—Ä–∏ –∑–∞ —ç–ø–æ—Ö—É\n",
    "        avg_train_loss = running_loss / len(train_loader)\n",
    "        mlflow.log_metric(\"train_loss\", avg_train_loss, step=epoch)\n",
    "        # --- –í–∞–ª–∏–¥–∞—Ü–∏—è –Ω–∞ –∫–∞–∂–¥–æ–π —ç–ø–æ—Ö–µ --\n",
    "        model.eval() # –ü–µ—Ä–µ–≤–æ–¥–∏–º –º–æ–¥–µ–ª—å –≤ —Ä–µ–∂–∏–º –æ—Ü–µ–Ω–∫–∏\n",
    "        val_loss = 0.0\n",
    "        val_mae = 0.0\n",
    "        with torch.no_grad(): # –û—Ç–∫–ª—é—á–∞–µ–º —Ä–∞—Å—á–µ—Ç –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤\n",
    "            for inputs, labels in val_loader:\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                # –°—á–∏—Ç–∞–µ–º MAE –≤—Ä—É—á–Ω—É\n",
    "                val_mae += torch.abs(outputs - labels).sum().item()\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        avg_val_mae = val_mae / len(val_subset)\n",
    "        mlflow.log_metric(\"val_loss\", avg_val_loss, step=epoch)\n",
    "        mlflow.log_metric(\"val_mae\", avg_val_mae, step=epoch)\n",
    "        print(f\"Epoch [{epoch+1}/{model_params['epochs']}], rain oss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}, Val MAE: {avg_val_mae:.4f}\")\n",
    "\n",
    "    # --- –û—Ü–µ–Ω–∫–∞ –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö ---\n",
    "    model.eval()\n",
    "    test_mae = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            outputs = model(inputs)\n",
    "            test_mae += torch.abs(outputs - labels).sum().item()\n",
    "    \n",
    "    final_mae = test_mae / len(test_dataset)\n",
    "    print(f'\\nTest MAE: {final_mae:.2f}')\n",
    "    # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫\n",
    "    metrics = {\"mae\": final_mae}\n",
    "    mlflow.log_metrics(metrics)\n",
    "    print(f\"Metrics logged: {metrics}\")\n",
    "    \n",
    "    # --- –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–∞–º–æ–π –º–æ–¥–µ–ª–∏ ---\n",
    "    mlflow.pytorch.log_model(\n",
    "        model,\n",
    "        artifact_path=\"lstm-model\"\n",
    "    )\n",
    "\n",
    "    print(\"Training finished.\")\n",
    "\n",
    "    # # --- –°–æ–∑–¥–∞–µ–º –ø—Ä–æ—Å—Ç—É—é LSTM –º–æ–¥–µ–ª—å ---\n",
    "    # model = Sequential()\n",
    "    # model.add(LSTM(16, input_shape=(n_timesteps, n_features), return_sequences=True)) # return_sequences=True, –µ—Å–ª–∏ —Å–ª–µ–¥—É—é—â–∏–π —Å–ª–æ–π —Ç–æ–∂–µ LSTM\n",
    "    # model.add(Dropout(0.2))\n",
    "    # model.add(LSTM(8))\n",
    "    # model.add(Dropout(0.2))\n",
    "    # model.add(Dense(1)) # –û–¥–∏–Ω –≤—ã—Ö–æ–¥, —Ç–∞–∫ –∫–∞–∫ –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ–º –æ–¥–Ω–æ —á–∏—Å–ª–æ - RUL\n",
    "\n",
    "    # # –ö–æ–º–ø–∏–ª–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å\n",
    "    # model.compile(optimizer=model_params['optimizer'], loss=model_params['loss'], metrics=['mae'])\n",
    "\n",
    "    # summary_list = []\n",
    "    # model.summary(print_fn=lambda x: summary_list.append(x))\n",
    "    # model_summary_string = \"\\n\".join(summary_list)\n",
    "\n",
    "    # mlflow.log_text(model_summary_string, 'model_summary.txt')\n",
    "\n",
    "    # model.summary()\n",
    "\n",
    "    # # --- –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å ---\n",
    "    # history = model.fit(X_train, y_train, \n",
    "    #                     epochs=model_params['epochs'], \n",
    "    #                     batch_size=model_params['batch_size'], \n",
    "    #                     validation_split=model_params['validation_split'], # –ò—Å–ø–æ–ª—å–∑—É–µ–º —á–∞—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –Ω–∞ –ª–µ—Ç—É\n",
    "    #                     callbacks=[mlflow.keras.MLflowCallback()],\n",
    "    #                     verbose=1)\n",
    "\n",
    "    # # --- –û—Ü–µ–Ω–∏–≤–∞–µ–º –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö ---\n",
    "    # loss, mae = model.evaluate(X_test, y_test, verbose=0)\n",
    "    # print(f'\\nTest MAE: {mae:.2f}')\n",
    "\n",
    "    # metrics = {\n",
    "    #     \"mae\": mae\n",
    "    # }\n",
    "    # mlflow.log_metrics(metrics)\n",
    "    # print(f\"Metrics logged: {metrics}\")\n",
    "\n",
    "    # # --- –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–∞–º–æ–π –º–æ–¥–µ–ª–∏ ---\n",
    "    # mlflow.keras.log_model(\n",
    "    #     model,\n",
    "    #     artifact_path=\"lstm-model\", # –ù–∞–∑–≤–∞–Ω–∏–µ –ø–∞–ø–∫–∏ —Å –º–æ–¥–µ–ª—å—é –≤ MLflow\n",
    "    # )\n",
    "\n",
    "print(\"Model logged as an artifact.\")\n",
    "\n",
    "print(\"MLflow run finished successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
